\chapter{评估}
在本节中，我们进行全面评估以回答以下问题：
• RQ1：LLMalMorph 生成的恶意软件变体对广泛使用的防病毒引擎和机器学习分类器的检测具有多强的抗性？其规避能力与最近的对抗性恶意软件生成框架生成的变体相比如何？
• RQ2：不同转换策略间的代码编辑工作量有何差异？这对揭示 LLM 所犯错误类型有何启示？
• RQ3：生成的恶意软件变体是否保留了原始样本的语义和功能？

\section{评估设置}

\subsection{选择样本}
由于最新的恶意软件源代码稀缺，大多数恶意软件研究都集中在可执行文件上。我们检查了公共数据库 [38], [39]，发现大多数可用的 Windows 恶意软件源代码是 32 位的，因此我们将研究重点放在 32 位变体上。我们选择了能够编译成可运行可执行文件、并表现出可通过 VirusTotal 或 Hybrid Analysis 检测到的恶意行为（其 AV 检测率≥60\%）的样本。这产生了十个具有不同复杂性和类型的恶意软件候选样本。RansomWar 样本使用 GCC 编译，其余样本使用 Microsoft Visual Studio 2022\footnote{https://visualstudio.microsoft.com/vs/}编译（因为提供了 .sln 文件）。表 II 总结了选定样本的关键细节。对于 Conti 和 Babuk 勒索软件，我们的分析集中在负责加密的加密器组件上。有关样本的详细信息请参见附录 B。

\subsection{评估指标}
我们使用给定的评估指标：防病毒（AV）检测率（$R^{\hat{Ms}}$）。我们使用 VirusTotal 评估 AV 检测率，该平台使用来自不同供应商的多个 AV 引擎扫描样本。每个样本可用的检测器数量因可用性而异。令 $D$ 为可用检测器的集合，$\hat{D} \subseteq D$ 为将恶意软件变体标记为恶意的检测器集合。在第 k 次运行时，变体 $\hat{M_{s}}$ 的 AV 检测率 $R^{\hat{M_{s}}}_{k}$ 定义为 $R^{\hat{M_{s}}}_{k} = \frac{|\hat{D}|}{|D|} \times 100$，其中 $|.|$ 表示两个集合的大小。

每个样本将进行$k$次运行，并计算平均检测率$R^{\hat{M_{s}}}=\frac{1}{k} \sum_{i=1}^{k} R_{k}^{\hat{M_{s}}}$。我们在实验中设定 k=3 以解释不同运行间的变异性。我们还使用 Hybrid Analysis，该工具包含静态分析、基于机器学习的分析以及使用不同引擎的多重扫描分析。检测性能以每个恶意软件样本及其变体在 k 次运行上的平均百分比表示。我们使用这两个工具的免费版本，并通过其各自的 API 自动化样本上传、结果检索和后处理。

\subsection{策略导向的机器学习分类器攻击成功率 (ASR)}
攻击成功率 (Attack Success Rate, ASR) 是评估对抗攻击的广泛使用的指标 [20], [40]，即生成的恶意软件变体成功逃避目标系统检测的比例。我们针对三种基于机器学习的恶意软件分类器评估 ASR：Malconv [41]、Malgraph [42] 和一个训练好的 ResNet50 恶意软件分类器 [43]。模型细节详见附录 E。令 M 为一个原始恶意软件样本，将我们的策略 s 应用于所有修改文件 $\hat{F} \subseteq F$ 并为 $j$ 个转换函数生成变体 $V_{s}^{M} = \{\hat{M_{1}}, \hat{M_{2}}, ..., \hat{M_{j}}\}$。对于给定的目标分类器 $C$，令 $\hat{V_{s,C}^{M}} = \{ \hat{M} \in V_{s}^{M} : C(\hat{M}) = benign\}$ 为成功逃避 $C$ 的变体子集。则攻击成功率为 $ASR = \frac{|\hat{V_{s,C}^{M}}|}{|V_{s}^{M}|} \times 100$。其中 $|.|$ 表示集合的大小。

\subsection{策略导向的代码编辑工作量 ($W_{s}^{M}$)}
该指标基于需要手动编辑以编译LLM生成代码的总代码行数来比较策略 $s$。值越高表明需要更广泛的手动干预，意味着LLM在该策略下犯了更严重的错误。对于给定的恶意软件 $M$，令 $\hat{F} \subseteq F$ 表示 $F$ 个文件中被修改的文件数量。恶意软件 $M$ 和策略 $s$ 的编辑工作量 $W_s^{M}$ 定义为在文件 $\hat{F}$ 中所有转换后的函数 $\{f_{1}^{i}, f_{2}^{i}... f_{j}^{i}\}$ 上编辑（添加、修改或删除）的总代码行数，计算公式为 $W_{s}^{M}=\sum_{i=1}^{\hat{F}} \sum_{t=1}^{j} L_{edit}(f_{t}^{i})$，其中 $L_{edit}$ 统计函数 $\hat{f_{t}^{i}}$ 被编辑代码的行数。

\subsection{人力投入量化指标 ($H_{s}^{M}$)}
该指标衡量针对每种策略调试和配置恶意软件中转换后函数所需的人力投入。它量化了生成一个成功编译的 PE 文件所需的总工时。对于给定的恶意软件 $M$ 和代码转换策略 $s$，人力投入 $H_{s}^{M}$ 的计算公式为 $H_{s}^{M} = \sum_{i=1}^{\hat{F}} \sum_{t=1}^{j} ManHours(\hat{f_{t}^{i}})$。此处，求和表示在策略 $s$ 下，在修改文件 $\hat{F}$ 中所有转换后的函数 $\{f_{1}^{i},f_{2}^{i}...f_{j}^{i}\}$ 上所花费的总工时。

\subsection{功能保留指标 ($\Phi^{M}$)}
该指标评估了经 LLMalMorph 转换后，恶意软件语义在变体中保留的程度。由于可执行文件固有的复杂性，尚无精确方法能判断恶意软件 $M$ 与其变种 $\hat{M}$ 之间的语义等价性 [44]。因此，文献中遵循的评估方法包括比较恶意软件与其变体之间的 API 调用序列 [22]，或通过在沙箱中运行来比较恶意软件及其变体的行为 [20], [23]。

我们采用类似方法，并利用最长公共子序列 (lcs) 算法来比较 $M$ 和 $\hat{M}$ 之间的 API 调用序列。转换后的变体必须保留原始的 API 调用顺序，允许存在不破坏此序列的额外调用。API 调用序列使用专有沙箱收集。归一化的最长公共子序列定义为 $\hat{lcs}(M, \hat{M})= \frac{lcs(M, \hat{M})}{Length(API(M))}$，其中分母是 $M$ 的 API 序列长度。分数范围从 0 到 1，1 表示完全相同的 API 序列。最后，我们计算功能保留率 $\Phi^{M} = \frac{|\hat{M} \in \psi^{\hat{M}}:\hat{lcs}(M,\hat{M}) \geq \delta|}{|\psi^{\hat{M}}|} \times 100$。

此处，$\psi^{\hat{M}}$（总变体集）定义为所有 AV 检测率 $R^{\hat{M_{s}}}$ 低于 $M$ 的基线检测率的恶意软件变体 $\hat{M}$ 的集合。分子代表 $\psi^{\hat{M}}$ 中保留了语义等价性的子集的大小，我们通过考虑归一化的最长公共子序列得分（其值大于预定义阈值 δ）来确定该子集，而 $|\psi^{\hat{M}}|$ 是整个总变体集的大小。我们通过经验分析恶意软件变体和原始样本，选择 $\delta$ 的值为 0.96。我们选取不同样本在离散值集上的恶意软件变体，并将其上传到 Triage Sandbox\footnote{https://tria.ge/}。我们分析了变体和原始恶意软件样本的报告，以比较行为指标、注册表修改、网络调用等。我们观察到，在某些情况下，行为漂移在分数低于 0.96 时开始出现，而在其他情况下，即使分数略高于该值，功能等价性也得以保持。然而，大多数保留了关键行为的变体得分在 0.96 或以下。因此，我们选择 $\delta = 0.96$ 作为上限，以确保被接受的变体在 API 序列和执行行为上保持高度相似性。

\section{模型选择}
虽然 LLMalMorph 可以利用任何 LLM 生成恶意软件变体，但我们选择 Codestral-22B [8] 作为我们的主要 LLM。我们精心设计的提示包含许多需要遵循的约束和指示。我们观察到 Codestral 模型能够比其他模型更精确地遵循这些特定指令来变异函数。此外，Codestral 为我们的用例提供了一组均衡的特性——220 亿参数、12 GB 模型大小和 32K 上下文窗口——并且与具有更高硬件要求的模型相比，它在长距离仓库级代码补全任务上具有卓越性能 [4], [9]。

\section{实现细节}
在 LLMalMorph 中，Function Mutator 内的 Extractor 子模块使用 Tree-sitter Parser\footnote{https://tree-sitter.github.io/tree-sitter/} 的 Python 绑定实现，利用其基于 C 的运行时进行高效解析。对于 LLM，我们使用了 Ollama\footnote{https://ollama.com/}，它便于本地 LLM 执行而无需外部 API 依赖，并提供了一个基于 Python 的接口。我们的实验设置包括一台配备 252 GB RAM 和 48 个处理器的 RTX 3090 GPU 服务器，以及一台配置了 VirtualBox 用于恶意软件编译的 Windows 10 虚拟机。LLMalMorph 的核心实现主要使用 Python 开发，部分组件（例如基于 lcs 的语义指标计算）使用 C++ 实现。

\section{评估结果与分析}
我们使用算法 \ref{alg:Function Transformation Using LLM} 和 \ref{alg:Malware Variant Generation} 对要修改的文件进行优先级排序，按函数数量升序排列。这假设对源代码了解有限的攻击者会针对函数较少的文件，以最小化工作量并最大化修改文件的数量。如果出现平局，则随机选择文件。我们依次修改每个文件内的函数，但这可能会忽略对恶意软件行为至关重要的关键函数。自动化分离恶意函数具有挑战性，因为看似良性的函数（例如，简单的线程管理）可能促成恶意活动。我们的目标是评估这种简单的顺序方法是否能在不损害功能的情况下产生规避性变体。有关文件选择标准以及每个样本选择要修改的函数数量的标准，请参见附录 C。